---
format: html
---

## `r fontawesome::fa("table", fill = "#5A5A5A", a11y = "sem")` Step 1. What data type(s)?

In order to determine the most appropriate and effective chart type, you first need to determine what type(s) of data you're working with. 

::: panel-tabset

## **`r fontawesome::fa("temperature-quarter", fill = "#5A5A5A", a11y = "sem")` Ex 1:** Ocean Temperatures

Let's say we're interested in visualizing **temporal variation in bottom temperature** at Mohawk Reef (Santa Barbara, CA), a near-shore rocky reef and one of the [Santa Barbara Coastal (SBC) LTER](https://sbclter.msi.ucsb.edu/) research sites. To do so, we'll use SBC LTER data, [SBC LTER: Ocean: Currents and Biogeochemistry: Moored CTD and ADCP data from Mohawk Outside Spar (MKO), ongoing since 2005](https://pasta.lternet.edu/package/eml/knb-lter-sbc/2007/16), available for download on the [EDI Data Portal](https://portal.edirepository.org/nis/home.jsp).

::: callout-important
## Warning: Large data file!
**Do not attempt to push raw data to GitHub** -- adding your `raw-data/` folder (or equivalent) to your `.gitignore` is highly recommmended. You may download the cleaned `mohawk_cleaned.rds` file [here](https://github.com/UCSB-MEDS/data-viz-practice/blob/main/clean-data/mohawk_temps.rds).
:::

The raw data file contains 87 variables and >473,000 observations across 18 years (2005 - 2022) (data have been interpolated to a 20 min interval) -- cleaning involves selecting only variables of interest,  coercing variables to the appropriate data type, adding month abbreviations, and assessing missing data (find the [cleaning script here](https://github.com/UCSB-MEDS/data-viz-practice/blob/main/data-wrangling/ocean-temps.R)).

Below are 10 randomly sampled rows from our cleaned data:

```{r}
#| eval: true
#| echo: true
#| message: false
#..........................load packages.........................
library(tidyverse)

#......................read in cleaned data......................
mko_clean <- readRDS(here::here("clean-data", "mohawk_temps.rds"))

#....................randomly sample 10 rows.....................
set.seed(12345) 
(random_mko_sample <- dplyr::slice_sample(mko_clean, n = 10))
```

We are working with both **numeric data** (bottom temperature, `Temp_bot`) and **categorical data** (months, `month`). Further we have several (well, *many*) observations per group (month).

## **`r fontawesome::fa("tree-city", fill = "#5A5A5A", a11y = "sem")` Ex 2:** Urban Trees

## **`r fontawesome::fa("sun", fill = "#5A5A5A", a11y = "sem")` Ex 3:** CA Drought

For this example, we'll be using the [#tidytuesday](https://github.com/rfordatascience/tidytuesday) [Drought Conditions in the US](https://github.com/rfordatascience/tidytuesday/tree/master/data/2022/2022-06-14) data set (posted on June 14, 2022). 

::: callout-important
## TidyTuesday provides "tamed", but not fully wrangled data
Learn more about the original data, courtesy of [US Drought Monitor](https://droughtmonitor.unl.edu/DmData/DataDownload/DSCI.aspx), by checking out the [tidytuesday GitHub repo](https://github.com/rfordatascience/tidytuesday/tree/master/data/2022/2022-06-14).
:::

The original [drought.csv](https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-06-14/drought.csv) data file (as posted on the tidytuesday GitHub repo) contains 14 variables and >73,000 observations. Weekly assessments of drought & wet conditions are made for each US state (and the District of Columbia) between 1895 - 2022 and reported as percent land area falling into each [Drought Classification Category](https://droughtmonitor.unl.edu/About/AbouttheData/DroughtClassification.aspx). Cleaning involves formatting dates and state names, converting drought classification categories and associated area percentages from wide to long format, and filtering for years of interest (2012 - 2022) (find the [cleaning script here](https://github.com/UCSB-MEDS/ggplot2-workflow/blob/main/data-wrangling/drought.R)).

Below are the first 12 rows from our cleaned data:

```{r}
#| eval: true
#| echo: true
#| message: false

#......................read in cleaned data......................
drought_clean <- readRDS(here::here("clean-data", "us_drought.rds"))

#..................print first 12 rows of data...................
head(drought_clean, 12)
```
Let's say we're interested in exploring trends in California drought and wet conditions from 2012 - 2022. We'll be working with one **categorical variable** (condition, `condition_long`), **one numeric variable** (percent area impacted, `perc_area`) and one **ordered numeric variable** (year, `year`).

:::