---
format: html
---

## `r fontawesome::fa("table", fill = "#5A5A5A", a11y = "sem")` Step 1. What data type(s)?

In order to determine the most appropriate and effective chart type, you first need to determine what type(s) of data you're working with. 

::: panel-tabset

## **`r fontawesome::fa("temperature-quarter", fill = "#5A5A5A", a11y = "sem")` Ex 1:** Ocean Temperatures

Let's say we're interested in visualizing **temporal variation in bottom temperature** at Mohawk Reef (Santa Barbara, CA), a near-shore rocky reef and one of the [Santa Barbara Coastal (SBC) LTER](https://sbclter.msi.ucsb.edu/) research sites. To do so, we'll use SBC LTER data, [SBC LTER: Ocean: Currents and Biogeochemistry: Moored CTD and ADCP data from Mohawk Outside Spar (MKO), ongoing since 2005](https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-sbc&identifier=2007), available for download on the [EDI Data Portal](https://portal.edirepository.org/nis/home.jsp).

::: callout-important
## Warning: Large data file!
**Do not attempt to push raw data to GitHub** -- adding your `raw-data/` folder (or equivalent) to your `.gitignore` is highly recommmended. You may download the cleaned `mohawk_cleaned.rds` file [here](https://github.com/UCSB-MEDS/data-viz-practice/blob/main/clean-data/mohawk_temps.rds).
:::

The raw data file contains 87 variables and >473,000 observations across 18 years (2005 - 2022) (data have been interpolated to a 20 min interval) -- cleaning involves selecting only variables of interest,  coercing variables to the appropriate data type, adding month abbreviations, and assessing missing data (find the [cleaning script here](https://github.com/UCSB-MEDS/ggplot2-workflow/blob/main/data-cleaning/ocean-temps-cleaning.R)).

Below are 10 randomly sampled rows from our cleaned data:

```{r}
#| eval: true
#| echo: true
#| message: false
#..........................load packages.........................
library(tidyverse)

#......................read in cleaned data......................
mko_clean <- readRDS(here::here("clean-data", "mohawk_temps.rds"))

#....................randomly sample 10 rows.....................
set.seed(123) 
(random_mko_sample <- dplyr::slice_sample(mko_clean, n = 10))
```

We are working with both **numeric data** (bottom temperature, `Temp_bot`) and **categorical data** (months, `month`). Further we have several (well, *many*) observations per group (month).

## **`r fontawesome::fa("money-bill-1", fill = "#5A5A5A", a11y = "sem")` Ex 2:** Wages

In honor of [Women's History Month](https://womenshistorymonth.gov/) we'll be using the [#tidytuesday](https://github.com/rfordatascience/tidytuesday) [Women in the Workforce](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-03-05) data set (posted on March 5, 2019) to explore **differences in salaries between males and females across occupations**.

The original [jobs_gender.csv](https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv) data file (as posted on the tidytuesday GitHub repo) contains 12 variables and >2,000 observations -- each row represents a different occupation and associated wage and employment statistics for the years 2013 - 2016. Cleaning involves removing occupations with missing salary data,  calculating some additional values (average salary for males and females by occupation, the percentage of males for each occupation type, difference in salary between males and females by occupation), and re-leveling the `perc_group_label` factor (which groups occupations by those that are 75% female, 45-55% female, and 75% male). Two cleaned data sets are available: [`all_jobs.rds`](https://github.com/UCSB-MEDS/ggplot2-workflow/blob/main/clean-data/all_jobs.rds) (contains all occupations with wage data from the original data set, across all available years) and [`select_jobs.rds`](https://github.com/UCSB-MEDS/ggplot2-workflow/blob/main/clean-data/select_jobs.rds) (contains 10 occupations from each of the following categories: occupations that are 75%+ women, 45-55% women, and 75%+ men, for the year 2016 only), which we'll use for plotting below. **NOTE:** These categories, which are represented by the variable, `perc_group_label` (factor), have already been reordered during the cleaning stage. Find the [cleaning script here](https://github.com/UCSB-MEDS/ggplot2-workflow/blob/main/data-cleaning/salaries-cleaning.R).

::: callout-important
## TidyTuesday provides "tamed", but not fully wrangled data
Learn more about the original data, courtesy of the [Census Bureau](https://www.census.gov/data/tables/time-series/demo/industry-occupation/median-earnings.html), by checking out the [tidytuesday GitHub repo](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-03-05).
:::

Below are 10 randomly sampled rows from our cleaned data (`select_jobs.rds`):

```{r}
#| eval: true
#| echo: true
#| message: false
#..........................load packages.........................
library(tidyverse)

#......................read in cleaned data......................
select_jobs <- readRDS(here::here("clean-data", "select_jobs.rds"))

#....................randomly sample 10 rows.....................
set.seed(123) 
(random_jobs_sample <- dplyr::slice_sample(select_jobs, n = 10))
```

We are working with **categorical data** (occupations, `occupation`), and **numeric data** ($ earned by men and women in a given occupation, `total_earnings_male` & `total_earnings_female`).

## **`r fontawesome::fa("sun-plant-wilt", fill = "#5A5A5A", a11y = "sem")` Ex 3:** CA Drought

For this example, we'll be using the [#tidytuesday](https://github.com/rfordatascience/tidytuesday) [Drought Conditions in the US](https://github.com/rfordatascience/tidytuesday/tree/master/data/2022/2022-06-14) data set (posted on June 14, 2022) to explore **drought and wet conditions in the state of California through time**. 

::: callout-important
## TidyTuesday provides "tamed", but not fully wrangled data
Learn more about the original data, courtesy of [US Drought Monitor](https://droughtmonitor.unl.edu/DmData/DataDownload/DSCI.aspx), by checking out the [tidytuesday GitHub repo](https://github.com/rfordatascience/tidytuesday/tree/master/data/2022/2022-06-14).
:::

The original [drought.csv](https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-06-14/drought.csv) data file (as posted on the tidytuesday GitHub repo) contains 14 variables and >73,000 observations. Weekly assessments of drought & wet conditions are made for each US state (and the District of Columbia) between 1895 - 2022 and reported as percent land area falling into each [Drought Classification Category](https://droughtmonitor.unl.edu/About/AbouttheData/DroughtClassification.aspx). Cleaning involves formatting dates and state names, converting drought classification categories and associated area percentages from wide to long format, and filtering for years of interest (2012 - 2022) (find the [cleaning script here](https://github.com/UCSB-MEDS/ggplot2-workflow/blob/main/data-cleaning/drought-cleaning.R)).

Below are the first 12 rows from our cleaned data:

```{r}
#| eval: true
#| echo: true
#| message: false

#......................read in cleaned data......................
drought_clean <- readRDS(here::here("clean-data", "us_drought.rds"))

#..................print first 12 rows of data...................
head(drought_clean, 12)
```
Let's say we're interested in exploring trends in California drought and wet conditions from 2012 - 2022. We'll be working with one **categorical variable** (condition, `condition_long`), **one numeric variable** (percent area impacted, `perc_area`) and one **ordered numeric variable** (year, `year`).

:::